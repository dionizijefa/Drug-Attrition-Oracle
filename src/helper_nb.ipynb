{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14462191-1382-42e5-9e94-69e6356c690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d860aa-45d7-4939-8fe5-8472664353bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40e906be-5eee-4b19-917f-340daec1e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from deslib.des.knora_e import KNORAE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import torch\n",
    "from time import time\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "48638fd4-f5fe-4de7-9d71-da48a1afcec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl = pd.read_csv('/home/dionizije/Documents/drug_attrition_oracle/data/chembl_4_smiles.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbd18c14-92ee-41e6-be16-e41f197ca7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chembl_id</th>\n",
       "      <th>pubchem_cid</th>\n",
       "      <th>smiles</th>\n",
       "      <th>parent_smiles</th>\n",
       "      <th>chembl_tox</th>\n",
       "      <th>withdrawn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>CHEMBL1237066</td>\n",
       "      <td>62859</td>\n",
       "      <td>O=C([O-])C(O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)...</td>\n",
       "      <td>O=C([O-])C(O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)...</td>\n",
       "      <td>Safe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>CHEMBL2010412</td>\n",
       "      <td>452192</td>\n",
       "      <td>C[n+]1c2cc(N)ccc2cc2ccc(N)cc21.Nc1ccc2cc3ccc(N...</td>\n",
       "      <td>missing</td>\n",
       "      <td>Safe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>CHEMBL1200747</td>\n",
       "      <td>62358</td>\n",
       "      <td>CC(O)C(=O)O.N</td>\n",
       "      <td>CC(O)C(=O)O.N</td>\n",
       "      <td>Safe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>CHEMBL2106975</td>\n",
       "      <td>61102</td>\n",
       "      <td>O=C([O-])O.[K+]</td>\n",
       "      <td>O=C([O-])O.[K+]</td>\n",
       "      <td>Safe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>CHEMBL1255943</td>\n",
       "      <td>2723891</td>\n",
       "      <td>Cl.N[C@@H](CCC(=O)O)C(=O)O</td>\n",
       "      <td>Cl.N[C@@H](CCC(=O)O)C(=O)O</td>\n",
       "      <td>Safe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10391</th>\n",
       "      <td>CHEMBL1200691</td>\n",
       "      <td>8896</td>\n",
       "      <td>CC(=O)[O-].CC(=O)[O-].[Mg+2]</td>\n",
       "      <td>CC(=O)[O-].CC(=O)[O-].[Mg+2]</td>\n",
       "      <td>Safe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10524</th>\n",
       "      <td>CHEMBL2106123</td>\n",
       "      <td>13136</td>\n",
       "      <td>O=C([O-])CC(O)(CC(=O)[O-])C(=O)[O-].O=C([O-])C...</td>\n",
       "      <td>O=C([O-])CC(O)(CC(=O)[O-])C(=O)[O-].O=C([O-])C...</td>\n",
       "      <td>Safe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10531</th>\n",
       "      <td>CHEMBL2364968</td>\n",
       "      <td>90661668</td>\n",
       "      <td>CC(C)C[C@H]1C(=O)N2CCC[C@H]2[C@]2(O)O[C@](NC(=...</td>\n",
       "      <td>missing</td>\n",
       "      <td>Safe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10560</th>\n",
       "      <td>CHEMBL261772</td>\n",
       "      <td>missing</td>\n",
       "      <td>C=C1c2c(Cl)ccc(O)c2C(=O)C2=C(O)[C@]3(O)C(=O)C(...</td>\n",
       "      <td>C=C1c2c(Cl)ccc(O)c2C(=O)C2=C(O)[C@]3(O)C(=O)C(...</td>\n",
       "      <td>Safe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10571</th>\n",
       "      <td>CHEMBL282468</td>\n",
       "      <td>6209</td>\n",
       "      <td>C[N+](C)(C)CCO.[Cl-]</td>\n",
       "      <td>C[N+](C)(C)CCO.[Cl-]</td>\n",
       "      <td>Safe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           chembl_id pubchem_cid  \\\n",
       "464    CHEMBL1237066       62859   \n",
       "700    CHEMBL2010412      452192   \n",
       "842    CHEMBL1200747       62358   \n",
       "1376   CHEMBL2106975       61102   \n",
       "1409   CHEMBL1255943     2723891   \n",
       "...              ...         ...   \n",
       "10391  CHEMBL1200691        8896   \n",
       "10524  CHEMBL2106123       13136   \n",
       "10531  CHEMBL2364968    90661668   \n",
       "10560   CHEMBL261772     missing   \n",
       "10571   CHEMBL282468        6209   \n",
       "\n",
       "                                                  smiles  \\\n",
       "464    O=C([O-])C(O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)...   \n",
       "700    C[n+]1c2cc(N)ccc2cc2ccc(N)cc21.Nc1ccc2cc3ccc(N...   \n",
       "842                                        CC(O)C(=O)O.N   \n",
       "1376                                     O=C([O-])O.[K+]   \n",
       "1409                          Cl.N[C@@H](CCC(=O)O)C(=O)O   \n",
       "...                                                  ...   \n",
       "10391                       CC(=O)[O-].CC(=O)[O-].[Mg+2]   \n",
       "10524  O=C([O-])CC(O)(CC(=O)[O-])C(=O)[O-].O=C([O-])C...   \n",
       "10531  CC(C)C[C@H]1C(=O)N2CCC[C@H]2[C@]2(O)O[C@](NC(=...   \n",
       "10560  C=C1c2c(Cl)ccc(O)c2C(=O)C2=C(O)[C@]3(O)C(=O)C(...   \n",
       "10571                               C[N+](C)(C)CCO.[Cl-]   \n",
       "\n",
       "                                           parent_smiles chembl_tox  withdrawn  \n",
       "464    O=C([O-])C(O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)...       Safe          0  \n",
       "700                                              missing       Safe          0  \n",
       "842                                        CC(O)C(=O)O.N       Safe          0  \n",
       "1376                                     O=C([O-])O.[K+]       Safe          0  \n",
       "1409                          Cl.N[C@@H](CCC(=O)O)C(=O)O       Safe          0  \n",
       "...                                                  ...        ...        ...  \n",
       "10391                       CC(=O)[O-].CC(=O)[O-].[Mg+2]       Safe          0  \n",
       "10524  O=C([O-])CC(O)(CC(=O)[O-])C(=O)[O-].O=C([O-])C...       Safe          0  \n",
       "10531                                            missing       Safe          0  \n",
       "10560  C=C1c2c(Cl)ccc(O)c2C(=O)C2=C(O)[C@]3(O)C(=O)C(...       Safe          0  \n",
       "10571                               C[N+](C)(C)CCO.[Cl-]       Safe          0  \n",
       "\n",
       "[77 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chembl.loc[chembl['smiles'].str.contains('\\.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f919e4fd-74dc-4753-a14f-c12fd6992254",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StringMethods' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-338-52353bb62938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchembl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smiles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'StringMethods' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "chembl['smiles'].str.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fc64f-29d4-408b-8c36-abefdf9afb2b",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6c85504a-10f7-4c11-aacc-cb6e5d4b54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = { # values for boostrap can be either True or False # values of max_depth are integers from 6 to 20\n",
    "        \"max_iter\": Integer(10, 1000),\n",
    "        \"learning_rate\": Real(0.001, 1),  \n",
    "        \"min_samples_leaf\": Integer(1, 30)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ddef17c8-6c9e-42ad-8689-639bd7a33fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf = HistGradientBoostingClassifier(early_stopping=True, validation_fraction=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9e1869c8-fe88-4038-87bc-35f9baabde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_bayes_search = BayesSearchCV(forest_clf, search_space, n_iter=32, # specify how many iterations\n",
    "                                    scoring=\"roc_auc\", n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a9ec70b8-83c7-4c7e-905c-ae1ceee4c4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=HistGradientBoostingClassifier(early_stopping=True,\n",
       "                                                       validation_fraction=0.15),\n",
       "              n_iter=32, n_jobs=-1, scoring='roc_auc',\n",
       "              search_spaces={'learning_rate': Real(low=0.001, high=1, prior='uniform', transform='identity'),\n",
       "                             'max_iter': Integer(low=10, high=1000, prior='uniform', transform='identity'),\n",
       "                             'min_samples_leaf': Integer(low=1, high=30, prior='uniform', transform='identity')})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_bayes_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a13c6eab-8df0-4674-a076-e9b205b514ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingClassifier(early_stopping=True,\n",
       "                               learning_rate=0.01619991660275452, max_iter=25,\n",
       "                               min_samples_leaf=12, validation_fraction=0.15)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_bayes_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c87f2bd-3fe1-4085-926c-73f0e32bf9b5",
   "metadata": {},
   "source": [
    "# AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f1f0c8fc-b331-4da2-8ea5-e0723ebee397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6878546912287747"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_bayes_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4391b20-5a8f-4d43-9ad8-9d118d146d46",
   "metadata": {},
   "source": [
    "# ROC auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "34387ada-0467-41fb-adf3-6465bc36b13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6895023895534506"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_bayes_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a30d355e-13f3-4076-9282-cbb28cb4379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aps = []\n",
    "aucs = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    #knorae = KNORAE(pool_classifiers)\n",
    "    #knorae.fit()\n",
    "    log_probs = clf.predict_proba(X_test)[:, 1]\n",
    "    ap = average_precision_score(y_test, log_probs)\n",
    "    roc_auc = roc_auc_score(y_test, log_probs)\n",
    "    aps.append(ap)\n",
    "    aucs.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "93c90e3d-7c1c-4c12-ad21-b0dac32eca9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14099473491817066"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2398445c-106a-4dbe-bc7c-6562d4d87d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6449456398734204"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e85aa7-901c-4d1e-9fbd-1149d3d83aef",
   "metadata": {},
   "source": [
    "# Knora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ff9967e8-de0f-4bb5-8730-aa989b77d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aps = []\n",
    "aucs = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train, X_dsel, y_train, y_dsel = train_test_split(X_train, y_train, test_size=0.5)\n",
    "    \n",
    "    clf = forest_bayes_search.best_estimator_\n",
    "    clf.fit(X_train, y_train)\n",
    "    knorae = KNORAE(clf)\n",
    "    knorae.fit(X_dsel, y_dsel)\n",
    "    \n",
    "    log_probs = clf.predict_proba(X_test)[:, 1]\n",
    "    ap = average_precision_score(y_test, log_probs)\n",
    "    roc_auc = roc_auc_score(y_test, log_probs)\n",
    "    aps.append(ap)\n",
    "    aucs.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a3b4acc3-b1c2-4b80-9573-0ad9bda0d34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1549412394889774"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5598ccce-4a2c-478f-b852-d89b9c0dcb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263718833458845"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27c825-9db6-440a-9a3f-790cea9fd67c",
   "metadata": {},
   "source": [
    "## Complementary models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3f746405-9495-46cf-bdd6-f2a152d87b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dao import DrugAttritionOracle\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from utils.metrics import table_metrics_trees\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "f2e71ac9-71fd-4601-9d25-f057234fca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/processing_pipeline/TDC_predictions/train_subtasks_predictions.csv', index_col=0)\n",
    "test = pd.read_csv('../data/processing_pipeline/TDC_predictions/test_subtasks_predictions.csv', index_col=0)\n",
    "file = open('../production/complementary_model/random_forest_classifier.pkl', 'rb')\n",
    "y_train = train['wd_consensus_1']\n",
    "y_test = test['wd_consensus_1']\n",
    "X_train = train.drop(columns=['chembl_id', 'standardized_smiles', 'wd_consensus_1'])\n",
    "X_test = test.drop(columns=['chembl_id', 'standardized_smiles', 'wd_consensus_1'])\n",
    "rf = pickle.load(file)\n",
    "node_feat_importance = pd.DataFrame(data=rf.feature_importances_[np.newaxis], columns=X_train.columns, index=[0])\n",
    "#feats = list(node_feat_importance.transpose().sort_values(0, ascending=False)[:13].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e99673e-e6ae-46f4-931d-5348e46a1e33",
   "metadata": {},
   "source": [
    "## Run on subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fbc68f-6b82-4e1d-8cc4-9134ccbc519e",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "101cdb14-171e-4b8b-a473-c4bd778adcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    " 'learning_rate' : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    " 'max_depth' : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " 'min_child_weight' : [ 1, 3, 5, 7 ],\n",
    " 'gamma': [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " 'colsample_bytree' : [ 0.3, 0.4, 0.5 , 0.7 ],\n",
    " 'scale_pos_weight': [5, 10, 15, 20, 35],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "59891089-2e3f-41ac-abb6-af70560613fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier = xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "a7ec59e2-4050-4f9e-bee6-d9d8277c803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_model=RandomizedSearchCV(clbassifier,param_distributions=params,n_iter=50,scoring='average_precision',n_jobs=-1,cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "7aa12a84-7e91-486d-be68-6e7c569bf778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scale_pos_weight': 10,\n",
       " 'min_child_weight': 5,\n",
       " 'max_depth': 15,\n",
       " 'learning_rate': 0.05,\n",
       " 'gamma': 0.2,\n",
       " 'colsample_bytree': 0.5}"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "f49fffcf-519c-4930-8e98-a714d5fa0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = xgboost.XGBClassifier(learning_rate=rs_model.best_params_['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "efccd087-2217-45ab-805c-472f9a408263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:59:12] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "c77321ef-5f4b-422b-9713-5183ec70105a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_booster().best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "754e7a8b-1975-4ec6-a385-6713fb31390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  6.3min finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:43:15] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100,...\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'scale_pos_weight': [5, 10, 15, 20,\n",
       "                                                             35]},\n",
       "                   scoring='average_precision', verbose=3)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "87088f66-0389-4545-aa9d-e7b1dedc2308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CYP2C9_Substrate_CarbonMangels</th>\n",
       "      <th>CYP2D6_Substrate_CarbonMangels</th>\n",
       "      <th>sr-are</th>\n",
       "      <th>CYP3A4_Veith</th>\n",
       "      <th>nr-er-lbd</th>\n",
       "      <th>nr-er</th>\n",
       "      <th>Solubility_AqSolDB</th>\n",
       "      <th>sr-atad5</th>\n",
       "      <th>Caco2_Wang</th>\n",
       "      <th>CYP2D6_Veith</th>\n",
       "      <th>...</th>\n",
       "      <th>CYP2C9_Veith</th>\n",
       "      <th>CYP1A2_Veith</th>\n",
       "      <th>HIA_Hou</th>\n",
       "      <th>nr-ppar-gamma</th>\n",
       "      <th>Clearance_Hepatocyte_AZ</th>\n",
       "      <th>Carcinogens_Languin</th>\n",
       "      <th>nr-aromatase</th>\n",
       "      <th>sr-mmp</th>\n",
       "      <th>sr-p53</th>\n",
       "      <th>predict_withdrawn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069458</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>0.506577</td>\n",
       "      <td>0.224221</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-2.688965</td>\n",
       "      <td>0.013394</td>\n",
       "      <td>-5.617864</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036047</td>\n",
       "      <td>0.006817</td>\n",
       "      <td>0.013520</td>\n",
       "      <td>0.008847</td>\n",
       "      <td>35.181927</td>\n",
       "      <td>0.286017</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>2.742608e-06</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.470054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.103099</td>\n",
       "      <td>0.232109</td>\n",
       "      <td>0.827061</td>\n",
       "      <td>0.226972</td>\n",
       "      <td>0.403773</td>\n",
       "      <td>0.932831</td>\n",
       "      <td>-5.085590</td>\n",
       "      <td>0.917336</td>\n",
       "      <td>-4.535133</td>\n",
       "      <td>0.156842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782207</td>\n",
       "      <td>0.921282</td>\n",
       "      <td>0.998295</td>\n",
       "      <td>0.011342</td>\n",
       "      <td>75.808525</td>\n",
       "      <td>0.374289</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>9.678469e-01</td>\n",
       "      <td>0.909958</td>\n",
       "      <td>0.606440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.340530</td>\n",
       "      <td>0.142519</td>\n",
       "      <td>0.457970</td>\n",
       "      <td>0.958183</td>\n",
       "      <td>0.235134</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>-3.813414</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>-4.795193</td>\n",
       "      <td>0.151132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874266</td>\n",
       "      <td>0.762396</td>\n",
       "      <td>0.996635</td>\n",
       "      <td>0.769668</td>\n",
       "      <td>33.605370</td>\n",
       "      <td>0.310629</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1.533354e-01</td>\n",
       "      <td>0.012377</td>\n",
       "      <td>0.485826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025499</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>0.081060</td>\n",
       "      <td>0.343454</td>\n",
       "      <td>0.095015</td>\n",
       "      <td>0.014898</td>\n",
       "      <td>-3.072849</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>-3.959646</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322632</td>\n",
       "      <td>0.068863</td>\n",
       "      <td>0.991903</td>\n",
       "      <td>0.148467</td>\n",
       "      <td>113.047005</td>\n",
       "      <td>0.615662</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>5.591495e-04</td>\n",
       "      <td>0.049619</td>\n",
       "      <td>0.129884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.417281</td>\n",
       "      <td>0.264848</td>\n",
       "      <td>0.112804</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.802562</td>\n",
       "      <td>0.937043</td>\n",
       "      <td>-5.873740</td>\n",
       "      <td>0.248247</td>\n",
       "      <td>-3.773222</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841268</td>\n",
       "      <td>0.853914</td>\n",
       "      <td>0.999501</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>74.288340</td>\n",
       "      <td>0.583670</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>1.606945e-01</td>\n",
       "      <td>0.145084</td>\n",
       "      <td>0.681620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.458754</td>\n",
       "      <td>0.308566</td>\n",
       "      <td>0.111702</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.715382</td>\n",
       "      <td>-0.882686</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>-4.659957</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109648</td>\n",
       "      <td>0.207328</td>\n",
       "      <td>0.873437</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>32.886288</td>\n",
       "      <td>0.352992</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>6.340616e-07</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.449080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.167058</td>\n",
       "      <td>0.508774</td>\n",
       "      <td>0.665901</td>\n",
       "      <td>0.023806</td>\n",
       "      <td>0.548024</td>\n",
       "      <td>0.058295</td>\n",
       "      <td>-1.635835</td>\n",
       "      <td>0.725651</td>\n",
       "      <td>-5.748230</td>\n",
       "      <td>0.772372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330940</td>\n",
       "      <td>0.088069</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>69.781120</td>\n",
       "      <td>0.486183</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>2.883503e-02</td>\n",
       "      <td>0.026883</td>\n",
       "      <td>0.631011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.115259</td>\n",
       "      <td>0.038823</td>\n",
       "      <td>0.233657</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.361210</td>\n",
       "      <td>0.060816</td>\n",
       "      <td>-3.895102</td>\n",
       "      <td>0.067972</td>\n",
       "      <td>-4.211524</td>\n",
       "      <td>0.011219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393423</td>\n",
       "      <td>0.027980</td>\n",
       "      <td>0.996202</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>1.042210</td>\n",
       "      <td>0.252291</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>1.127547e-03</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.668740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.234541</td>\n",
       "      <td>0.107649</td>\n",
       "      <td>0.050168</td>\n",
       "      <td>0.015203</td>\n",
       "      <td>0.033033</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>-1.089897</td>\n",
       "      <td>0.025235</td>\n",
       "      <td>-4.674285</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365868</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>0.859953</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>8.636477</td>\n",
       "      <td>0.658230</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>4.709835e-07</td>\n",
       "      <td>0.031638</td>\n",
       "      <td>0.381551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.101601</td>\n",
       "      <td>0.354584</td>\n",
       "      <td>0.049068</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.029996</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-1.950665</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>-5.334961</td>\n",
       "      <td>0.103228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206292</td>\n",
       "      <td>0.355981</td>\n",
       "      <td>0.997504</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>22.778858</td>\n",
       "      <td>0.329084</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>4.625961e-04</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.454892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CYP2C9_Substrate_CarbonMangels  CYP2D6_Substrate_CarbonMangels    sr-are  \\\n",
       "0                          0.069458                        0.004521  0.506577   \n",
       "1                          0.103099                        0.232109  0.827061   \n",
       "2                          0.340530                        0.142519  0.457970   \n",
       "3                          0.025499                        0.010939  0.081060   \n",
       "4                          0.417281                        0.264848  0.112804   \n",
       "..                              ...                             ...       ...   \n",
       "390                        0.458754                        0.308566  0.111702   \n",
       "391                        0.167058                        0.508774  0.665901   \n",
       "392                        0.115259                        0.038823  0.233657   \n",
       "393                        0.234541                        0.107649  0.050168   \n",
       "394                        0.101601                        0.354584  0.049068   \n",
       "\n",
       "     CYP3A4_Veith  nr-er-lbd     nr-er  Solubility_AqSolDB  sr-atad5  \\\n",
       "0        0.224221   0.075100  0.000071           -2.688965  0.013394   \n",
       "1        0.226972   0.403773  0.932831           -5.085590  0.917336   \n",
       "2        0.958183   0.235134  0.000681           -3.813414  0.002442   \n",
       "3        0.343454   0.095015  0.014898           -3.072849  0.001167   \n",
       "4        0.030651   0.802562  0.937043           -5.873740  0.248247   \n",
       "..            ...        ...       ...                 ...       ...   \n",
       "390      0.000344   0.003962  0.715382           -0.882686  0.000556   \n",
       "391      0.023806   0.548024  0.058295           -1.635835  0.725651   \n",
       "392      0.000564   0.361210  0.060816           -3.895102  0.067972   \n",
       "393      0.015203   0.033033  0.000702           -1.089897  0.025235   \n",
       "394      0.852381   0.029996  0.000103           -1.950665  0.001679   \n",
       "\n",
       "     Caco2_Wang  CYP2D6_Veith  ...  CYP2C9_Veith  CYP1A2_Veith   HIA_Hou  \\\n",
       "0     -5.617864      0.001843  ...      0.036047      0.006817  0.013520   \n",
       "1     -4.535133      0.156842  ...      0.782207      0.921282  0.998295   \n",
       "2     -4.795193      0.151132  ...      0.874266      0.762396  0.996635   \n",
       "3     -3.959646      0.000006  ...      0.322632      0.068863  0.991903   \n",
       "4     -3.773222      0.007486  ...      0.841268      0.853914  0.999501   \n",
       "..          ...           ...  ...           ...           ...       ...   \n",
       "390   -4.659957      0.000003  ...      0.109648      0.207328  0.873437   \n",
       "391   -5.748230      0.772372  ...      0.330940      0.088069  0.997442   \n",
       "392   -4.211524      0.011219  ...      0.393423      0.027980  0.996202   \n",
       "393   -4.674285      0.002292  ...      0.365868      0.016981  0.859953   \n",
       "394   -5.334961      0.103228  ...      0.206292      0.355981  0.997504   \n",
       "\n",
       "     nr-ppar-gamma  Clearance_Hepatocyte_AZ  Carcinogens_Languin  \\\n",
       "0         0.008847                35.181927             0.286017   \n",
       "1         0.011342                75.808525             0.374289   \n",
       "2         0.769668                33.605370             0.310629   \n",
       "3         0.148467               113.047005             0.615662   \n",
       "4         0.001056                74.288340             0.583670   \n",
       "..             ...                      ...                  ...   \n",
       "390       0.005758                32.886288             0.352992   \n",
       "391       0.000385                69.781120             0.486183   \n",
       "392       0.000975                 1.042210             0.252291   \n",
       "393       0.000113                 8.636477             0.658230   \n",
       "394       0.000008                22.778858             0.329084   \n",
       "\n",
       "     nr-aromatase        sr-mmp    sr-p53  predict_withdrawn  \n",
       "0        0.001043  2.742608e-06  0.009950           0.470054  \n",
       "1        0.004148  9.678469e-01  0.909958           0.606440  \n",
       "2        0.000067  1.533354e-01  0.012377           0.485826  \n",
       "3        0.000727  5.591495e-04  0.049619           0.129884  \n",
       "4        0.002604  1.606945e-01  0.145084           0.681620  \n",
       "..            ...           ...       ...                ...  \n",
       "390      0.000028  6.340616e-07  0.007156           0.449080  \n",
       "391      0.000086  2.883503e-02  0.026883           0.631011  \n",
       "392      0.000168  1.127547e-03  0.001459           0.668740  \n",
       "393      0.000151  4.709835e-07  0.031638           0.381551  \n",
       "394      0.002449  4.625961e-04  0.000100           0.454892  \n",
       "\n",
       "[395 rows x 39 columns]"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "1d43a094-c228-4da8-b53b-ef9cc0710f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal threshold F1 withdrawn class random forest\n",
    "optimal_f1_score = []\n",
    "optimal_threshold = []\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "    predictions_df = train_pred_df.copy()\n",
    "    predictions_df['predicted_class'] = 0\n",
    "    predictions_df.loc[predictions_df['probabilities'] > threshold, 'predicted_class'] = 1\n",
    "    optimal_f1_score.append(f1_score(\n",
    "        predictions_df['target'], predictions_df['predicted_class'], average='binary'\n",
    "    ))\n",
    "    optimal_threshold.append(threshold)\n",
    "\n",
    "optimal_f1_index = np.argmax(np.array(optimal_f1_score))\n",
    "optimal_threshold = optimal_threshold[optimal_f1_index]\n",
    "\n",
    "test_pred_df = pd.DataFrame({'probabilities': predictions[:, 1],\n",
    "                            'wd_consensus_1': y_test,\n",
    "                            \n",
    "                             'predicted_class': rs_model.best_estimator_.predict(X_test)})\n",
    "results = table_metrics_trees(test_pred_df, 'wd_consensus_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "6be1e920-bb30-404b-977a-25bee0362fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP withdrawn</th>\n",
       "      <th>AP approved</th>\n",
       "      <th>AUROC withdrawn</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Precision withdrawn</th>\n",
       "      <th>Recall withdrawn</th>\n",
       "      <th>Precision approved</th>\n",
       "      <th>Recall approved</th>\n",
       "      <th>True positives</th>\n",
       "      <th>True negatives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.397815</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.832989</td>\n",
       "      <td>0.629392</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.921833</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>12</td>\n",
       "      <td>342</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AP withdrawn  AP approved  AUROC withdrawn  Balanced accuracy  \\\n",
       "0      0.397815     0.790555         0.832989           0.629392   \n",
       "\n",
       "   Precision withdrawn  Recall withdrawn  Precision approved  Recall approved  \\\n",
       "0                  0.5          0.292683            0.921833         0.966102   \n",
       "\n",
       "   True positives  True negatives  False positives  False negatives  \n",
       "0              12             342               12               29  "
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711f7ac-e0bc-4dcf-bb40-67b1ec1751ee",
   "metadata": {},
   "source": [
    "## Shap Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dd175192-7198-431a-8a04-01554481c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import table_metrics_trees\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "656cb557-622e-406b-bfca-88293e5e83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/dionizije/Documents/drug_attrition_oracle/data/processing_pipeline/TDC_predictions/train_subtasks_predictions.csv', index_col=0)\n",
    "test = pd.read_csv('/home/dionizije/Documents/drug_attrition_oracle/data/processing_pipeline/TDC_predictions/test_subtasks_predictions.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7d525d34-5800-4c40-9ec5-ce81874db528",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.2,\n",
    "        colsample_bytree=0.4,\n",
    "        scale_pos_weight=10,\n",
    "        n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "360f5a78-6154-4683-8070-030afc3c15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "withdrawn_col = 'wd_consensus_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b34cda95-619b-40a3-83bd-55b5dfd4fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[withdrawn_col]\n",
    "y_test = test[withdrawn_col]\n",
    "X_train = train.drop(columns=['chembl_id', 'standardized_smiles', withdrawn_col])\n",
    "X_test = test.drop(columns=['chembl_id', 'standardized_smiles', withdrawn_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "de179698-0afd-4ef6-b19f-8ea7ecac4c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dionizije/anaconda3/envs/withdrawn/lib/python3.6/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:38:20] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.4, gamma=0.2, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3371c7e0-f9ec-4c95-816e-ca462fae8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_features = list(\n",
    "    pd.DataFrame(\n",
    "        columns=X_train.columns,\n",
    "        data=abs(np.mean(shap_values.values, axis=0))[np.newaxis]\n",
    "    ).transpose().sort_values(0, ascending=False)[:5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "06185f3b-0de6-4350-941f-371f234db93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ClinTox', 'predict_withdrawn', 'nr-er', 'CYP1A2_Veith', 'nr-ppar-gamma']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "497623c6-549c-4ec5-9362-8d97f0cfa963",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict_proba(X_test, ntree_limit=classifier.get_booster().best_ntree_limit)\n",
    "test_pred_df = pd.DataFrame({'probabilities': predictions[:, 1],\n",
    "                             withdrawn_col: y_test,\n",
    "                             'predicted_class': classifier.predict(X_test, ntree_limit=classifier.get_booster().best_ntree_limit)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "80d83c06-838e-49a8-bb2f-70f656a09894",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = table_metrics_trees(test_pred_df, withdrawn_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1f4bb632-1be6-41fa-a800-04de30aaa12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AP withdrawn</th>\n",
       "      <th>AP approved</th>\n",
       "      <th>AUROC withdrawn</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Precision withdrawn</th>\n",
       "      <th>Recall withdrawn</th>\n",
       "      <th>Precision approved</th>\n",
       "      <th>Recall approved</th>\n",
       "      <th>True positives</th>\n",
       "      <th>True negatives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.794605</td>\n",
       "      <td>0.806394</td>\n",
       "      <td>0.730157</td>\n",
       "      <td>0.44898</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.923729</td>\n",
       "      <td>22</td>\n",
       "      <td>327</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1 score  AP withdrawn  AP approved  AUROC withdrawn  Balanced accuracy  \\\n",
       "0  0.488889      0.389249     0.794605         0.806394           0.730157   \n",
       "\n",
       "   Precision withdrawn  Recall withdrawn  Precision approved  Recall approved  \\\n",
       "0              0.44898          0.536585            0.945087         0.923729   \n",
       "\n",
       "   True positives  True negatives  False positives  False negatives  \n",
       "0              22             327               27               19  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff81f06-1883-4712-96cc-005ecc3657e9",
   "metadata": {},
   "source": [
    "## ViÅ¡nja ADME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "be45f9e1-4501-434f-b468-8fa910a2a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/dionizije/Documents/drug_attrition_oracle/data/processing_pipeline/TDC_predictions/train_subtasks_predictions.csv', index_col=0)\n",
    "test = pd.read_csv('/home/dionizije/Documents/drug_attrition_oracle/data/processing_pipeline/TDC_predictions/test_subtasks_predictions.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "368d57a4-8ba5-4b4d-90db-e61bc06e3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tox = pd.read_csv('/home/dionizije/Downloads/MasterDB_20Sep2021_ADMEPPredictor_Tox.csv', index_col=0)\n",
    "adme_phys = pd.read_csv('/home/dionizije/Downloads/MasterDB_20Sep2021_ADMEPPredictor_PhysChem.csv', index_col=0)\n",
    "rdkit = pd.read_csv(\"/home/dionizije/Documents/drug_attrition_oracle/data/processing_pipeline/descriptors/rdkit_descriptors.csv\")\n",
    "japtox = pd.read_csv(\"/home/dionizije/Documents/drug_attrition_oracle/data/processing_pipeline/descriptors/ADME-JapTox-RDKIT.csv\").iloc[:, :34]\n",
    "toxprint = pd.read_csv(\"/home/dionizije/Documents/drug_attrition_oracle/data/processing_pipeline/descriptors/toxprint_descriptors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "230a9b92-2dcf-4fed-b1f4-39c606eb304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxprint_list = [\"chain:alkaneBranch_neopentyl_C5\",\n",
    "    \"bond:C(=O)N_carbamate_thio_generic\",\n",
    "    \"chain:aromaticAlkene_Ph-C4_phenylbutadiene\",\n",
    "    \"chain:aromaticAlkane_Ph-C1_acyclic_generic\",\n",
    "    \"ring:aromatic_benzene\",\n",
    "    \"bond:COH_alcohol_aliphatic_generic\",\n",
    "    \"bond:COH_alcohol_sec-alkyl\",\n",
    "    \"ring:aromatic_phenyl\",\n",
    "    \"bond:C(=O)N_carboxamide_(NHR)\",\n",
    "    \"group:aminoAcid_aminoAcid_generic\",\n",
    "    \"chain:aromaticAlkane_Ph-C1-Ph\",\n",
    "    \"bond:C=O_carbonyl_ab-unsaturated_generic\",\n",
    "    \"chain:alkaneCyclic_ethyl_C2_(connect_noZ)\",\n",
    "    \"bond:CC(=O)C_ketone_aliphatic_acyclic\",\n",
    "    \"chain:aromaticAlkane_Ar-C-Ar\",\n",
    "    \"bond:CC(=O)C_ketone_generic\",\n",
    "    \"chembl_id\"]\n",
    "toxprint = toxprint[toxprint_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "b7d1bbba-836d-4c44-978d-aa80cc43904b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain:alkaneBranch_neopentyl_C5</th>\n",
       "      <th>bond:C(=O)N_carbamate_thio_generic</th>\n",
       "      <th>chain:aromaticAlkene_Ph-C4_phenylbutadiene</th>\n",
       "      <th>chain:aromaticAlkane_Ph-C1_acyclic_generic</th>\n",
       "      <th>ring:aromatic_benzene</th>\n",
       "      <th>bond:COH_alcohol_aliphatic_generic</th>\n",
       "      <th>bond:COH_alcohol_sec-alkyl</th>\n",
       "      <th>ring:aromatic_phenyl</th>\n",
       "      <th>bond:C(=O)N_carboxamide_(NHR)</th>\n",
       "      <th>group:aminoAcid_aminoAcid_generic</th>\n",
       "      <th>chain:aromaticAlkane_Ph-C1-Ph</th>\n",
       "      <th>bond:C=O_carbonyl_ab-unsaturated_generic</th>\n",
       "      <th>chain:alkaneCyclic_ethyl_C2_(connect_noZ)</th>\n",
       "      <th>bond:CC(=O)C_ketone_aliphatic_acyclic</th>\n",
       "      <th>chain:aromaticAlkane_Ar-C-Ar</th>\n",
       "      <th>bond:CC(=O)C_ketone_generic</th>\n",
       "      <th>chembl_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CHEMBL1091250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CHEMBL1601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CHEMBL2110774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CHEMBL385517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CHEMBL1201779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CHEMBL918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CHEMBL926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CHEMBL370252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CHEMBL1201336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CHEMBL905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chain:alkaneBranch_neopentyl_C5  bond:C(=O)N_carbamate_thio_generic  \\\n",
       "0                                   0                                   0   \n",
       "1                                   0                                   0   \n",
       "2                                   0                                   0   \n",
       "3                                   1                                   0   \n",
       "4                                   0                                   0   \n",
       "...                               ...                                 ...   \n",
       "2498                                0                                   0   \n",
       "2499                                0                                   0   \n",
       "2500                                0                                   0   \n",
       "2501                                0                                   0   \n",
       "2502                                0                                   0   \n",
       "\n",
       "      chain:aromaticAlkene_Ph-C4_phenylbutadiene  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "...                                          ...   \n",
       "2498                                           0   \n",
       "2499                                           0   \n",
       "2500                                           0   \n",
       "2501                                           0   \n",
       "2502                                           0   \n",
       "\n",
       "      chain:aromaticAlkane_Ph-C1_acyclic_generic  ring:aromatic_benzene  \\\n",
       "0                                              0                      1   \n",
       "1                                              1                      1   \n",
       "2                                              1                      1   \n",
       "3                                              0                      0   \n",
       "4                                              1                      1   \n",
       "...                                          ...                    ...   \n",
       "2498                                           1                      1   \n",
       "2499                                           1                      1   \n",
       "2500                                           0                      1   \n",
       "2501                                           0                      1   \n",
       "2502                                           1                      1   \n",
       "\n",
       "      bond:COH_alcohol_aliphatic_generic  bond:COH_alcohol_sec-alkyl  \\\n",
       "0                                      0                           0   \n",
       "1                                      1                           1   \n",
       "2                                      0                           0   \n",
       "3                                      1                           0   \n",
       "4                                      0                           0   \n",
       "...                                  ...                         ...   \n",
       "2498                                   0                           0   \n",
       "2499                                   0                           0   \n",
       "2500                                   0                           0   \n",
       "2501                                   0                           0   \n",
       "2502                                   0                           0   \n",
       "\n",
       "      ring:aromatic_phenyl  bond:C(=O)N_carboxamide_(NHR)  \\\n",
       "0                        0                              0   \n",
       "1                        1                              1   \n",
       "2                        1                              0   \n",
       "3                        0                              0   \n",
       "4                        1                              1   \n",
       "...                    ...                            ...   \n",
       "2498                     1                              1   \n",
       "2499                     0                              0   \n",
       "2500                     0                              0   \n",
       "2501                     1                              0   \n",
       "2502                     0                              0   \n",
       "\n",
       "      group:aminoAcid_aminoAcid_generic  chain:aromaticAlkane_Ph-C1-Ph  \\\n",
       "0                                     0                              0   \n",
       "1                                     1                              0   \n",
       "2                                     0                              1   \n",
       "3                                     1                              0   \n",
       "4                                     1                              0   \n",
       "...                                 ...                            ...   \n",
       "2498                                  0                              0   \n",
       "2499                                  0                              0   \n",
       "2500                                  0                              0   \n",
       "2501                                  0                              0   \n",
       "2502                                  0                              0   \n",
       "\n",
       "      bond:C=O_carbonyl_ab-unsaturated_generic  \\\n",
       "0                                            1   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "...                                        ...   \n",
       "2498                                         0   \n",
       "2499                                         0   \n",
       "2500                                         1   \n",
       "2501                                         0   \n",
       "2502                                         0   \n",
       "\n",
       "      chain:alkaneCyclic_ethyl_C2_(connect_noZ)  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             1   \n",
       "4                                             0   \n",
       "...                                         ...   \n",
       "2498                                          0   \n",
       "2499                                          0   \n",
       "2500                                          1   \n",
       "2501                                          0   \n",
       "2502                                          0   \n",
       "\n",
       "      bond:CC(=O)C_ketone_aliphatic_acyclic  chain:aromaticAlkane_Ar-C-Ar  \\\n",
       "0                                         0                             0   \n",
       "1                                         0                             0   \n",
       "2                                         0                             1   \n",
       "3                                         0                             0   \n",
       "4                                         0                             0   \n",
       "...                                     ...                           ...   \n",
       "2498                                      0                             0   \n",
       "2499                                      0                             0   \n",
       "2500                                      0                             0   \n",
       "2501                                      0                             0   \n",
       "2502                                      0                             0   \n",
       "\n",
       "      bond:CC(=O)C_ketone_generic      chembl_id  \n",
       "0                               1  CHEMBL1091250  \n",
       "1                               0     CHEMBL1601  \n",
       "2                               0  CHEMBL2110774  \n",
       "3                               0   CHEMBL385517  \n",
       "4                               0  CHEMBL1201779  \n",
       "...                           ...            ...  \n",
       "2498                            0      CHEMBL918  \n",
       "2499                            0      CHEMBL926  \n",
       "2500                            1   CHEMBL370252  \n",
       "2501                            0  CHEMBL1201336  \n",
       "2502                            0      CHEMBL905  \n",
       "\n",
       "[2503 rows x 17 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "30d4033a-440f-4f00-ad7b-6e2ba0d138ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "japtox = japtox.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "49669abd-9482-42ca-a5f8-91147a32e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tox = tox.drop(columns=['test_train', 'drugbank_id', 'mw_ap', 'drugbank_three_class', 'sum', 'wd_consensus_1', 'wd_consensus_2', 'wd_consensus_3',\n",
    "                       'wd_consensus_1_NO_DISCONT', 'wd_consensus_2_NO_DISCONT', 'wd_consensus_3_NO_DISCONT'])\n",
    "adme_phys = adme_phys.drop(columns=['test_train', 'mw_ap', 'drugbank_three_class', 'sum', 'wd_consensus_1', 'wd_consensus_2', 'wd_consensus_3',\n",
    "                       'wd_consensus_1_NO_DISCONT', 'wd_consensus_2_NO_DISCONT', 'wd_consensus_3_NO_DISCONT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "73eed959-0e62-4c80-91bd-7382d8a966bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['predict_withdrawn', 'chembl_id', 'wd_consensus_1']]\n",
    "test = test[['predict_withdrawn', 'chembl_id', 'wd_consensus_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "9e443809-04aa-48e6-9ef7-3e91ff618236",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(tox, how='inner', on='chembl_id')\n",
    "train = train.merge(adme_phys, how='inner', on='chembl_id')\n",
    "train = train.drop_duplicates('chembl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae2f03-be03-4807-96fc-7268674fa4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "eef4ae31-0f29-425f-89a3-01eb3a50f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(rdkit, how='inner', on='chembl_id')\n",
    "test = test.merge(rdkit, how='inner', on='chembl_id')\n",
    "train = train.drop_duplicates('chembl_id')\n",
    "test = test.drop_duplicates('chembl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "30b09da2-027a-4b93-969e-8405a8b3eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(tox, how='inner', on='chembl_id')\n",
    "test = test.merge(adme_phys, how='inner', on='chembl_id')\n",
    "test = test.drop_duplicates('chembl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b6b8def7-1962-44de-bd3b-08a7cf128abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(japtox, how='inner', on='chembl_id')\n",
    "test = test.merge(japtox, how='inner', on='chembl_id')\n",
    "train = train.drop_duplicates('chembl_id')\n",
    "test = test.drop_duplicates('chembl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "890a5b79-793e-42f0-aab8-7a7dd76f01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(toxprint, how='inner', on='chembl_id')\n",
    "test = test.merge(toxprint, how='inner', on='chembl_id')\n",
    "train = train.drop_duplicates('chembl_id')\n",
    "test = test.drop_duplicates('chembl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "b465c5b9-2775-4e57-b16a-84af666937a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['wd_consensus_1']\n",
    "y_test = test['wd_consensus_1']\n",
    "\n",
    "X_train = train.drop(columns=['wd_consensus_1', 'chembl_id', 'standardized_smiles'])\n",
    "X_test = test.drop(columns=['wd_consensus_1', 'chembl_id', 'standardized_smiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "86941287-468c-4d69-abb8-54ea2738faa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CYP2C9_Substrate_CarbonMangels', 'CYP2D6_Substrate_CarbonMangels',\n",
       "       'sr-are', 'CYP3A4_Veith', 'nr-er-lbd', 'nr-er', 'Solubility_AqSolDB',\n",
       "       'sr-atad5', 'Caco2_Wang', 'CYP2D6_Veith', 'Skin Reaction', 'PPBR_AZ',\n",
       "       'Pgp_Broccatelli', 'BBB_Martins', 'nr-ar-lbd', 'VDss_Lombardo',\n",
       "       'CYP3A4_Substrate_CarbonMangels', 'Lipophilicity_AstraZeneca',\n",
       "       'LD50_Zhu', 'hERG', 'Bioavailability_Ma', 'nr-ahr', 'DILI', 'nr-ar',\n",
       "       'AMES', 'CYP2C19_Veith', 'ClinTox', 'Half_Life_Obach', 'sr-hse',\n",
       "       'CYP2C9_Veith', 'CYP1A2_Veith', 'HIA_Hou', 'nr-ppar-gamma',\n",
       "       'Clearance_Hepatocyte_AZ', 'Carcinogens_Languin', 'nr-aromatase',\n",
       "       'sr-mmp', 'sr-p53', 'predict_withdrawn',\n",
       "       'chain:alkaneBranch_neopentyl_C5', 'bond:C(=O)N_carbamate_thio_generic',\n",
       "       'chain:aromaticAlkene_Ph-C4_phenylbutadiene',\n",
       "       'chain:aromaticAlkane_Ph-C1_acyclic_generic', 'ring:aromatic_benzene',\n",
       "       'bond:COH_alcohol_aliphatic_generic', 'bond:COH_alcohol_sec-alkyl',\n",
       "       'ring:aromatic_phenyl', 'bond:C(=O)N_carboxamide_(NHR)',\n",
       "       'group:aminoAcid_aminoAcid_generic', 'chain:aromaticAlkane_Ph-C1-Ph',\n",
       "       'bond:C=O_carbonyl_ab-unsaturated_generic',\n",
       "       'chain:alkaneCyclic_ethyl_C2_(connect_noZ)',\n",
       "       'bond:CC(=O)C_ketone_aliphatic_acyclic', 'chain:aromaticAlkane_Ar-C-Ar',\n",
       "       'bond:CC(=O)C_ketone_generic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "09652761-2ebb-41df-92da-0c34c57ea243",
   "metadata": {},
   "outputs": [],
   "source": [
    "    params = {\n",
    "        'learning_rate': [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "        'max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
    "        'min_child_weight': [1, 3, 5, 7],\n",
    "        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "        'colsample_bytree': [0.3, 0.4, 0.5, 0.7],\n",
    "        'scale_pos_weight': [5, 10, 15, 20, 35],\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "ee2d90a8-79a3-457f-bb7f-1b2e79f51f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "0b9f3339-ec34-4490-8de9-9a517d22a843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 100 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 28.1min finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:16:59] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=6,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100,...\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500],\n",
       "                                        'scale_pos_weight': [5, 10, 15, 20,\n",
       "                                                             35]},\n",
       "                   scoring='average_precision', verbose=3)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_model = RandomizedSearchCV(classifier, param_distributions=params, n_iter=100, scoring='average_precision',\n",
    "                              n_jobs=-1, cv=6, verbose=3)\n",
    "rs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "3872b655-67ed-4dc6-8479-c4561ee3d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rs_model.best_estimator_.predict_proba(X_test)\n",
    "test_pred_df = pd.DataFrame({'probabilities': predictions[:, 1],\n",
    "                             withdrawn_col: y_test,\n",
    "                             'predicted_class': rs_model.predict(X_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "24f4003b-db27-4d21-a1cd-75884b21426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = table_metrics_trees(test_pred_df, withdrawn_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ebadb-d660-4670-812d-e9db23dc6cf2",
   "metadata": {},
   "source": [
    "* Predicted + toxprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "963cbba7-6a96-440f-9e11-f456aec2c46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AP withdrawn</th>\n",
       "      <th>AP approved</th>\n",
       "      <th>AUROC withdrawn</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Precision withdrawn</th>\n",
       "      <th>Recall withdrawn</th>\n",
       "      <th>Precision approved</th>\n",
       "      <th>Recall approved</th>\n",
       "      <th>True positives</th>\n",
       "      <th>True negatives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.417266</td>\n",
       "      <td>0.43451</td>\n",
       "      <td>0.785302</td>\n",
       "      <td>0.833953</td>\n",
       "      <td>0.756201</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.805085</td>\n",
       "      <td>29</td>\n",
       "      <td>285</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1 score  AP withdrawn  AP approved  AUROC withdrawn  Balanced accuracy  \\\n",
       "0  0.417266       0.43451     0.785302         0.833953           0.756201   \n",
       "\n",
       "   Precision withdrawn  Recall withdrawn  Precision approved  Recall approved  \\\n",
       "0             0.295918          0.707317            0.959596         0.805085   \n",
       "\n",
       "   True positives  True negatives  False positives  False negatives  \n",
       "0              29             285               69               12  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f59ec9-8272-40cd-a007-0cb868bddf39",
   "metadata": {},
   "source": [
    "* Predicted + rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "a78fe3c6-b985-4c65-9a6e-805585ec09aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AP withdrawn</th>\n",
       "      <th>AP approved</th>\n",
       "      <th>AUROC withdrawn</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Precision withdrawn</th>\n",
       "      <th>Recall withdrawn</th>\n",
       "      <th>Precision approved</th>\n",
       "      <th>Recall approved</th>\n",
       "      <th>True positives</th>\n",
       "      <th>True negatives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.365484</td>\n",
       "      <td>0.79933</td>\n",
       "      <td>0.789996</td>\n",
       "      <td>0.710004</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>20</td>\n",
       "      <td>330</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1 score  AP withdrawn  AP approved  AUROC withdrawn  Balanced accuracy  \\\n",
       "0  0.470588      0.365484      0.79933         0.789996           0.710004   \n",
       "\n",
       "   Precision withdrawn  Recall withdrawn  Precision approved  Recall approved  \\\n",
       "0             0.454545          0.487805            0.940171         0.932203   \n",
       "\n",
       "   True positives  True negatives  False positives  False negatives  \n",
       "0              20             330               24               21  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63958a4-6d1f-43cf-a8fb-9f084ddf4bc9",
   "metadata": {},
   "source": [
    "* Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "728555ad-1dcc-4b0a-a74b-8c40a223aa66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AP withdrawn</th>\n",
       "      <th>AP approved</th>\n",
       "      <th>AUROC withdrawn</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Precision withdrawn</th>\n",
       "      <th>Recall withdrawn</th>\n",
       "      <th>Precision approved</th>\n",
       "      <th>Recall approved</th>\n",
       "      <th>True positives</th>\n",
       "      <th>True negatives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453782</td>\n",
       "      <td>0.381002</td>\n",
       "      <td>0.793424</td>\n",
       "      <td>0.818038</td>\n",
       "      <td>0.757234</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.955836</td>\n",
       "      <td>0.855932</td>\n",
       "      <td>27</td>\n",
       "      <td>303</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1 score  AP withdrawn  AP approved  AUROC withdrawn  Balanced accuracy  \\\n",
       "0  0.453782      0.381002     0.793424         0.818038           0.757234   \n",
       "\n",
       "   Precision withdrawn  Recall withdrawn  Precision approved  Recall approved  \\\n",
       "0             0.346154          0.658537            0.955836         0.855932   \n",
       "\n",
       "   True positives  True negatives  False positives  False negatives  \n",
       "0              27             303               51               14  "
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dedb09b-101f-4001-a03c-612fccf81128",
   "metadata": {},
   "source": [
    "* RDKIT + predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "01694ce2-9149-4d5b-8b8a-1e21ea09068e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AP withdrawn</th>\n",
       "      <th>AP approved</th>\n",
       "      <th>AUROC withdrawn</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Precision withdrawn</th>\n",
       "      <th>Recall withdrawn</th>\n",
       "      <th>Precision approved</th>\n",
       "      <th>Recall approved</th>\n",
       "      <th>True positives</th>\n",
       "      <th>True negatives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.41791</td>\n",
       "      <td>0.467745</td>\n",
       "      <td>0.784435</td>\n",
       "      <td>0.828166</td>\n",
       "      <td>0.653783</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>14</td>\n",
       "      <td>342</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1 score  AP withdrawn  AP approved  AUROC withdrawn  Balanced accuracy  \\\n",
       "0   0.41791      0.467745     0.784435         0.828166           0.653783   \n",
       "\n",
       "   Precision withdrawn  Recall withdrawn  Precision approved  Recall approved  \\\n",
       "0             0.538462          0.341463            0.926829         0.966102   \n",
       "\n",
       "   True positives  True negatives  False positives  False negatives  \n",
       "0              14             342               12               27  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f9cdef-a69e-4774-b1b7-86940f95fd37",
   "metadata": {},
   "source": [
    "* adme + predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "421c90e9-dfa8-497a-a4a9-6a52804f60a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AP withdrawn</th>\n",
       "      <th>AP approved</th>\n",
       "      <th>AUROC withdrawn</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Precision withdrawn</th>\n",
       "      <th>Recall withdrawn</th>\n",
       "      <th>Precision approved</th>\n",
       "      <th>Recall approved</th>\n",
       "      <th>True positives</th>\n",
       "      <th>True negatives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.414414</td>\n",
       "      <td>0.403796</td>\n",
       "      <td>0.789654</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.714104</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.944615</td>\n",
       "      <td>0.867232</td>\n",
       "      <td>23</td>\n",
       "      <td>307</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1 score  AP withdrawn  AP approved  AUROC withdrawn  Balanced accuracy  \\\n",
       "0  0.414414      0.403796     0.789654         0.834711           0.714104   \n",
       "\n",
       "   Precision withdrawn  Recall withdrawn  Precision approved  Recall approved  \\\n",
       "0             0.328571          0.560976            0.944615         0.867232   \n",
       "\n",
       "   True positives  True negatives  False positives  False negatives  \n",
       "0              23             307               47               18  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1e9f4-af93-40bd-8251-b0cd658a0055",
   "metadata": {},
   "source": [
    "* tox only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "6d3b93ec-1b92-4c82-87b2-baf9df64497f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AP withdrawn</th>\n",
       "      <th>AP approved</th>\n",
       "      <th>AUROC withdrawn</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Precision withdrawn</th>\n",
       "      <th>Recall withdrawn</th>\n",
       "      <th>Precision approved</th>\n",
       "      <th>Recall approved</th>\n",
       "      <th>True positives</th>\n",
       "      <th>True negatives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.349915</td>\n",
       "      <td>0.798773</td>\n",
       "      <td>0.808185</td>\n",
       "      <td>0.582024</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.912234</td>\n",
       "      <td>0.968927</td>\n",
       "      <td>8</td>\n",
       "      <td>343</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1 score  AP withdrawn  AP approved  AUROC withdrawn  Balanced accuracy  \\\n",
       "0  0.266667      0.349915     0.798773         0.808185           0.582024   \n",
       "\n",
       "   Precision withdrawn  Recall withdrawn  Precision approved  Recall approved  \\\n",
       "0             0.421053          0.195122            0.912234         0.968927   \n",
       "\n",
       "   True positives  True negatives  False positives  False negatives  \n",
       "0               8             343               11               33  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546f47d-9c1e-4ff5-9873-832f736ddeec",
   "metadata": {},
   "source": [
    "* Results tox + physchem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "fb4528c6-0d9e-437d-a5fa-75db16ef9032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AP withdrawn</th>\n",
       "      <th>AP approved</th>\n",
       "      <th>AUROC withdrawn</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Precision withdrawn</th>\n",
       "      <th>Recall withdrawn</th>\n",
       "      <th>Precision approved</th>\n",
       "      <th>Recall approved</th>\n",
       "      <th>True positives</th>\n",
       "      <th>True negatives</th>\n",
       "      <th>False positives</th>\n",
       "      <th>False negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.384</td>\n",
       "      <td>0.369677</td>\n",
       "      <td>0.793242</td>\n",
       "      <td>0.834849</td>\n",
       "      <td>0.707937</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.945338</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>24</td>\n",
       "      <td>294</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1 score  AP withdrawn  AP approved  AUROC withdrawn  Balanced accuracy  \\\n",
       "0     0.384      0.369677     0.793242         0.834849           0.707937   \n",
       "\n",
       "   Precision withdrawn  Recall withdrawn  Precision approved  Recall approved  \\\n",
       "0             0.285714          0.585366            0.945338         0.830508   \n",
       "\n",
       "   True positives  True negatives  False positives  False negatives  \n",
       "0              24             294               60               17  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d367df-f594-486a-a34c-6865efc6f835",
   "metadata": {},
   "source": [
    "# WD Models with ATC codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0729c0d5-b4fd-4b7d-a491-37efb321d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.descriptors_list import toxprint_descriptors_10pct\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b4050a0a-1f95-44ff-89b5-61941c39cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/home/dionizije/Documents/drug_attrition_oracle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "433b9c71-032a-442b-be26-467e9d837460",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(root / 'data/processing_pipeline/train/train.csv')[['chembl_id', withdrawn_col]]\n",
    "train = train.sample(frac=1, random_state=0)  # shuffle\n",
    "test = pd.read_csv(root / 'data/processing_pipeline/test/test.csv')[['chembl_id', withdrawn_col]]\n",
    "toxprints = pd.read_csv(root / 'data/processing_pipeline/descriptors/toxprint_descriptors.csv')\n",
    "chembl_ids = toxprints['chembl_id']\n",
    "toxprints = toxprints[toxprint_descriptors_10pct] # drop mostly 0 zescriptors\n",
    "toxprints['chembl_id'] = chembl_ids\n",
    "master_atc = pd.read_csv(root / 'data/processing_pipeline/master_atc.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a12c859c-df4c-4706-9623-ac23ac088aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "toxprints.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in\n",
    "          toxprints.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "68a64e6b-bd33-4444-a2bc-0b31ad4a48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(master_atc, how='inner', on='chembl_id')\n",
    "test = test.merge(master_atc, how='inner', on='chembl_id')\n",
    "\n",
    "train = train.merge(toxprints, how='inner', on='chembl_id')\n",
    "test = test.merge(toxprints, how='inner', on='chembl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5a82ced7-4f97-4bde-9849-68f3bd8d4b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "    train['atc_code'] = train['atc_code'].str.split('0').str[0]\n",
    "    train['atc_code'] = train['atc_code'].str.split('1').str[0]\n",
    "\n",
    "    test['atc_code'] = test['atc_code'].str.split('0').str[0]\n",
    "    test['atc_code'] = test['atc_code'].str.split('1').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b3699c6c-f1ad-4b64-bee5-d3cf7dc3215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    'max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'colsample_bytree': [0.3, 0.4, 0.5, 0.7],\n",
    "    'scale_pos_weight': [5, 10, 15, 20, 35],\n",
    "    'n_estimators': [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "fc7fbd2a-799a-4720-a7ba-f5b9e0c044fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:23] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:24] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:24] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:25] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:26] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:27] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:27] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:28] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:28] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:29] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:30] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:31] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:31] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:32] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:33] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:33] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:34] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:35] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:35] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:36] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:36] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:37] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:37] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:38] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:39] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:39] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:40] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:41] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.6s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:42] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:43] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:44] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:44] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:45] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:45] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:46] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:47] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:47] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:48] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:48] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:49] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:50] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:51] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:51] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:52] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:53] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:53] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:54] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:55] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:55] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:56] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:57] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:58] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:58] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:59] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:00:00] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:00:00] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:00:01] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:00:02] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:00:03] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:00:03] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.3s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:00:04] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-217a4ccd4299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mpredict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mauroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0msorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0msorted_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/withdrawn/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/withdrawn/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    391\u001b[0m                                              max_fpr=max_fpr),\n\u001b[1;32m    392\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    394\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n",
      "\u001b[0;32m~/anaconda3/envs/withdrawn/lib/python3.6/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/withdrawn/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m\"\"\"Binary roc auc score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    224\u001b[0m                          \"is not defined in that case.\")\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "ap_overall = []\n",
    "atc_codes = []\n",
    "auroc_overall = []\n",
    "results = []\n",
    "for i in list(train['atc_code'].unique()):\n",
    "    train_subset = train.loc[train['atc_code'] == i]\n",
    "    test_subset = test.loc[test['atc_code'] == i]\n",
    "\n",
    "    cv_splitter = StratifiedKFold(\n",
    "    n_splits=6,\n",
    "    shuffle=True,\n",
    "    random_state=0)\n",
    "    \n",
    "    features_across_fold = []\n",
    "    ap_fold = []\n",
    "    auroc_fold = []\n",
    "    for k, (train_index, test_index) in enumerate(\n",
    "            cv_splitter.split(train_subset, train_subset[withdrawn_col])\n",
    "    ):\n",
    "        y_train = train_subset.iloc[train_index]['wd_consensus_1']\n",
    "        y_test = train_subset.iloc[test_index]['wd_consensus_1']\n",
    "        X_train = train_subset.iloc[train_index].drop(columns=['wd_consensus_1', 'chembl_id', 'atc_code'])\n",
    "        X_test = train_subset.iloc[test_index].drop(columns=['wd_consensus_1', 'chembl_id', 'atc_code'])\n",
    "\n",
    "        classifier = XGBClassifier()\n",
    "        rs_model = RandomizedSearchCV(classifier, param_distributions=params,\n",
    "                                      n_iter=1, scoring='average_precision',\n",
    "                                      n_jobs=-1, cv=6, verbose=3)\n",
    "        rs_model.fit(X_train, y_train)\n",
    "        predict_proba = rs_model.best_estimator_.predict_proba(X_test)\n",
    "        ap = average_precision_score(y_test, predict_proba[:, 1])\n",
    "        auroc = roc_auc_score(y_test, predict_proba[:, 1])\n",
    "        sorted_idx = rs_model.best_estimator_.feature_importances_.argsort()\n",
    "        sorted_importances = list(X_train.columns[sorted_idx][-10:])\n",
    "        features_across_fold.append(sorted_importances)\n",
    "        ap_fold.append(ap)\n",
    "        auroc_fold.append(auroc)\n",
    "    top_features = (pd.DataFrame(features_across_fold).melt().groupby('value').sum().sort_values('variable', ascending=False)[:10].index)\n",
    "    results.append(top_features)\n",
    "    atc_codes.append(i)\n",
    "    ap_overall.append(np.mean(ap_fold))\n",
    "    auroc_overall.append(np.mean(auroc_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "1c49887f-264d-4327-a995-2dfaa24d985f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['standardized_smiles'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-294-b4d02196fad6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wd_consensus_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wd_consensus_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_subset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wd_consensus_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chembl_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'standardized_smiles'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'atc_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_subset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wd_consensus_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chembl_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'standardized_smiles'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'atc_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/withdrawn/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4174\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m         )\n\u001b[1;32m   4176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/withdrawn/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/withdrawn/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/withdrawn/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['standardized_smiles'] not found in axis\""
     ]
    }
   ],
   "source": [
    "    results = []\n",
    "    atc_codes = []\n",
    "    columns = []\n",
    "    for i in list(train['atc_code'].unique()):\n",
    "        #try:\n",
    "            train_subset = train.loc[train['atc_code'] == i]\n",
    "            test_subset = test.loc[test['atc_code'] == i]\n",
    "\n",
    "            y_train = train_subset['wd_consensus_1']\n",
    "            y_test = test_subset['wd_consensus_1']\n",
    "            X_train = train_subset.drop(columns=['wd_consensus_1', 'chembl_id', 'standardized_smiles', 'atc_code'])\n",
    "            X_test = test_subset.drop(columns=['wd_consensus_1', 'chembl_id', 'standardized_smiles', 'atc_code'])\n",
    "\n",
    "            classifier = XGBClassifier()\n",
    "            rs_model = RandomizedSearchCV(classifier, param_distributions=params,\n",
    "                                          n_iter=100, scoring='average_precision',\n",
    "                                          n_jobs=-1, cv=6, verbose=3)\n",
    "            rs_model.fit(X_train, y_train)\n",
    "\n",
    "            predictions = rs_model.best_estimator_.predict_proba(X_test)\n",
    "            test_pred_df = pd.DataFrame({'probabilities': predictions[:, 1],\n",
    "                                         withdrawn_col: y_test,\n",
    "                                         'predicted_class': rs_model.predict(X_test)})\n",
    "            results.append(table_metrics_trees(test_pred_df, withdrawn_col).values[0])\n",
    "            columns.append(table_metrics_trees(test_pred_df, withdrawn_col).columns)\n",
    "            atc_codes.append(i)\n",
    "        #except:\n",
    "            #continue\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=columns[0], index=atc_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "7201be3f-7cb3-48ba-b346-2cd3273b6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, index=atc_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "dd6ad31d-5371-45a3-972f-3a4dd3612dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['mean_average_precision'] = ap_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "dec85fce-ea3e-481a-ad37-cb8265623256",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['mean_auroc'] = auroc_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "4d148e05-fe09-403d-9dfd-45af0dcc7d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>mean_average_precision</th>\n",
       "      <th>mean_auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>ring:hetero__5__Z_1_3-Z</td>\n",
       "      <td>bond:CC(=O)C_ketone_generic</td>\n",
       "      <td>bond:C(=O)N_carboxamide_generic</td>\n",
       "      <td>chain:aromaticAlkane_Ph-C1_acyclic_generic</td>\n",
       "      <td>chain:alkaneLinear_ethyl_C2(H_gt_1)</td>\n",
       "      <td>bond:COC_ether_aliphatic</td>\n",
       "      <td>bond:COC_ether_aliphatic__aromatic</td>\n",
       "      <td>bond:COH_alcohol_aliphatic_generic</td>\n",
       "      <td>bond:CN_amine_sec-NH_generic</td>\n",
       "      <td>ring:hetero__6_6__Z_generic</td>\n",
       "      <td>0.158193</td>\n",
       "      <td>0.507341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>bond:COH_alcohol_aliphatic_generic</td>\n",
       "      <td>bond:C(=O)N_carboxamide_generic</td>\n",
       "      <td>chain:alkaneLinear_ethyl_C2(H_gt_1)</td>\n",
       "      <td>bond:COH_alcohol_sec-alkyl</td>\n",
       "      <td>ring:aromatic_benzene</td>\n",
       "      <td>chain:aromaticAlkane_Ph-C1_acyclic_generic</td>\n",
       "      <td>bond:CN_amine_ter-N_aliphatic</td>\n",
       "      <td>bond:CC(=O)C_ketone_aliphatic_generic</td>\n",
       "      <td>chain:alkaneCyclic_hexyl_C6</td>\n",
       "      <td>bond:COC_ether_aliphatic</td>\n",
       "      <td>0.216338</td>\n",
       "      <td>0.647837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>ring:hetero__6__Z_generic</td>\n",
       "      <td>chain:alkaneBranch_isopropyl_C3</td>\n",
       "      <td>bond:C(=O)N_carboxamide_generic</td>\n",
       "      <td>chain:alkaneLinear_ethyl_C2(H_gt_1)</td>\n",
       "      <td>bond:COH_alcohol_aromatic</td>\n",
       "      <td>bond:CX_halide_aromatic-X_generic</td>\n",
       "      <td>chain:alkaneBranch_neopentyl_C5</td>\n",
       "      <td>ring:hetero__5__Z_1_3-Z</td>\n",
       "      <td>ring:hetero__6_6__Z_generic</td>\n",
       "      <td>chain:alkaneLinear_propyl_C3</td>\n",
       "      <td>0.242896</td>\n",
       "      <td>0.530556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>chain:alkaneBranch_neopentyl_C5</td>\n",
       "      <td>bond:CX_halide_aromatic-X_generic</td>\n",
       "      <td>ring:hetero__6__Z_generic</td>\n",
       "      <td>bond:C(=O)N_carboxamide_generic</td>\n",
       "      <td>chain:alkaneLinear_ethyl_C2(H_gt_1)</td>\n",
       "      <td>bond:CC(=O)C_ketone_aliphatic_generic</td>\n",
       "      <td>bond:COC_ether_aliphatic</td>\n",
       "      <td>bond:CN_amine_sec-NH_alkyl</td>\n",
       "      <td>chain:aromaticAlkane_Ph-C1_acyclic_generic</td>\n",
       "      <td>bond:COH_alcohol_sec-alkyl</td>\n",
       "      <td>0.248083</td>\n",
       "      <td>0.743365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>chain:alkaneLinear_propyl_C3</td>\n",
       "      <td>chain:alkaneBranch_neopentyl_C5</td>\n",
       "      <td>chain:alkaneLinear_ethyl_C2_(connect_noZ_CN=4)</td>\n",
       "      <td>chain:alkaneBranch_isopropyl_C3</td>\n",
       "      <td>bond:CX_halide_aromatic-X_generic</td>\n",
       "      <td>bond:C(=O)N_carboxamide_generic</td>\n",
       "      <td>bond:CN_amine_sec-NH_alkyl</td>\n",
       "      <td>bond:CN_amine_alicyclic_generic</td>\n",
       "      <td>ring:hetero__6__N_pyridine_generic</td>\n",
       "      <td>ring:hetero__5__Z_1_3-Z</td>\n",
       "      <td>0.195870</td>\n",
       "      <td>0.594190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>ring:aromatic_benzene</td>\n",
       "      <td>bond:COH_alcohol_aliphatic_generic</td>\n",
       "      <td>chain:alkaneBranch_isopropyl_C3</td>\n",
       "      <td>chain:alkaneLinear_propyl_C3</td>\n",
       "      <td>bond:CC(=O)C_ketone_generic</td>\n",
       "      <td>bond:CX_halide_aromatic-X_generic</td>\n",
       "      <td>bond:CN_amine_pri-NH2_generic</td>\n",
       "      <td>chain:aromaticAlkane_Ph-C1_cyclic</td>\n",
       "      <td>ring:hetero__6__N_pyridine_generic</td>\n",
       "      <td>bond:CC(=O)C_ketone_aliphatic_generic</td>\n",
       "      <td>0.233856</td>\n",
       "      <td>0.655864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>bond:CC(=O)C_ketone_generic</td>\n",
       "      <td>bond:COH_alcohol_aliphatic_generic</td>\n",
       "      <td>bond:CN_amine_sec-NH_alkyl</td>\n",
       "      <td>chain:alkaneBranch_isopropyl_C3</td>\n",
       "      <td>ring:hetero__5__Z_1_3-Z</td>\n",
       "      <td>chain:alkaneLinear_ethyl_C2(H_gt_1)</td>\n",
       "      <td>bond:CX_halide_aromatic-X_generic</td>\n",
       "      <td>chain:alkaneLinear_ethyl_C2_(connect_noZ_CN=4)</td>\n",
       "      <td>ring:aromatic_phenyl</td>\n",
       "      <td>chain:aromaticAlkane_Ph-C1_acyclic_generic</td>\n",
       "      <td>0.207821</td>\n",
       "      <td>0.707437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>bond:C(=O)N_carboxamide_generic</td>\n",
       "      <td>chain:alkaneLinear_ethyl_C2_(connect_noZ_CN=4)</td>\n",
       "      <td>bond:COH_alcohol_aliphatic_generic</td>\n",
       "      <td>chain:aromaticAlkane_Ph-C1_acyclic_generic</td>\n",
       "      <td>bond:C(=O)N_carboxamide_(NHR)</td>\n",
       "      <td>ring:aromatic_benzene</td>\n",
       "      <td>bond:CN_amine_sec-NH_generic</td>\n",
       "      <td>bond:CX_halide_aromatic-X_generic</td>\n",
       "      <td>ring:aromatic_phenyl</td>\n",
       "      <td>bond:C(=O)O_carboxylicAcid_alkyl</td>\n",
       "      <td>0.668128</td>\n",
       "      <td>0.793803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>chain:alkaneBranch_neopentyl_C5</td>\n",
       "      <td>ring:hetero__6__Z_generic</td>\n",
       "      <td>chain:alkaneLinear_propyl_C3</td>\n",
       "      <td>bond:COH_alcohol_aliphatic_generic</td>\n",
       "      <td>chain:alkaneLinear_ethyl_C2(H_gt_1)</td>\n",
       "      <td>ring:hetero__6_6__Z_generic</td>\n",
       "      <td>chain:aromaticAlkane_Ph-C1_acyclic_generic</td>\n",
       "      <td>bond:C(=O)N_carboxamide_generic</td>\n",
       "      <td>bond:COH_alcohol_aromatic</td>\n",
       "      <td>bond:COC_ether_aliphatic</td>\n",
       "      <td>0.123778</td>\n",
       "      <td>0.584656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>chain:alkaneCyclic_hexyl_C6</td>\n",
       "      <td>bond:COH_alcohol_aromatic</td>\n",
       "      <td>bond:C(=O)N_carboxamide_generic</td>\n",
       "      <td>bond:CX_halide_aromatic-X_generic</td>\n",
       "      <td>ring:hetero__6__Z_generic</td>\n",
       "      <td>ring:hetero__5__Z_1_3-Z</td>\n",
       "      <td>bond:CC(=O)C_ketone_aliphatic_generic</td>\n",
       "      <td>bond:C(=O)O_carboxylicAcid_generic</td>\n",
       "      <td>ring:aromatic_phenyl</td>\n",
       "      <td>chain:alkaneLinear_ethyl_C2(H_gt_1)</td>\n",
       "      <td>0.256457</td>\n",
       "      <td>0.688779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0  \\\n",
       "J             ring:hetero__5__Z_1_3-Z   \n",
       "A  bond:COH_alcohol_aliphatic_generic   \n",
       "G           ring:hetero__6__Z_generic   \n",
       "S     chain:alkaneBranch_neopentyl_C5   \n",
       "N        chain:alkaneLinear_propyl_C3   \n",
       "C               ring:aromatic_benzene   \n",
       "R         bond:CC(=O)C_ketone_generic   \n",
       "M     bond:C(=O)N_carboxamide_generic   \n",
       "L     chain:alkaneBranch_neopentyl_C5   \n",
       "D         chain:alkaneCyclic_hexyl_C6   \n",
       "\n",
       "                                                1  \\\n",
       "J                     bond:CC(=O)C_ketone_generic   \n",
       "A                 bond:C(=O)N_carboxamide_generic   \n",
       "G                 chain:alkaneBranch_isopropyl_C3   \n",
       "S               bond:CX_halide_aromatic-X_generic   \n",
       "N                 chain:alkaneBranch_neopentyl_C5   \n",
       "C              bond:COH_alcohol_aliphatic_generic   \n",
       "R              bond:COH_alcohol_aliphatic_generic   \n",
       "M  chain:alkaneLinear_ethyl_C2_(connect_noZ_CN=4)   \n",
       "L                       ring:hetero__6__Z_generic   \n",
       "D                       bond:COH_alcohol_aromatic   \n",
       "\n",
       "                                                2  \\\n",
       "J                 bond:C(=O)N_carboxamide_generic   \n",
       "A             chain:alkaneLinear_ethyl_C2(H_gt_1)   \n",
       "G                 bond:C(=O)N_carboxamide_generic   \n",
       "S                       ring:hetero__6__Z_generic   \n",
       "N  chain:alkaneLinear_ethyl_C2_(connect_noZ_CN=4)   \n",
       "C                 chain:alkaneBranch_isopropyl_C3   \n",
       "R                      bond:CN_amine_sec-NH_alkyl   \n",
       "M              bond:COH_alcohol_aliphatic_generic   \n",
       "L                    chain:alkaneLinear_propyl_C3   \n",
       "D                 bond:C(=O)N_carboxamide_generic   \n",
       "\n",
       "                                            3  \\\n",
       "J  chain:aromaticAlkane_Ph-C1_acyclic_generic   \n",
       "A                  bond:COH_alcohol_sec-alkyl   \n",
       "G         chain:alkaneLinear_ethyl_C2(H_gt_1)   \n",
       "S             bond:C(=O)N_carboxamide_generic   \n",
       "N             chain:alkaneBranch_isopropyl_C3   \n",
       "C                chain:alkaneLinear_propyl_C3   \n",
       "R             chain:alkaneBranch_isopropyl_C3   \n",
       "M  chain:aromaticAlkane_Ph-C1_acyclic_generic   \n",
       "L          bond:COH_alcohol_aliphatic_generic   \n",
       "D           bond:CX_halide_aromatic-X_generic   \n",
       "\n",
       "                                     4  \\\n",
       "J  chain:alkaneLinear_ethyl_C2(H_gt_1)   \n",
       "A                ring:aromatic_benzene   \n",
       "G            bond:COH_alcohol_aromatic   \n",
       "S  chain:alkaneLinear_ethyl_C2(H_gt_1)   \n",
       "N    bond:CX_halide_aromatic-X_generic   \n",
       "C          bond:CC(=O)C_ketone_generic   \n",
       "R              ring:hetero__5__Z_1_3-Z   \n",
       "M        bond:C(=O)N_carboxamide_(NHR)   \n",
       "L  chain:alkaneLinear_ethyl_C2(H_gt_1)   \n",
       "D            ring:hetero__6__Z_generic   \n",
       "\n",
       "                                            5  \\\n",
       "J                    bond:COC_ether_aliphatic   \n",
       "A  chain:aromaticAlkane_Ph-C1_acyclic_generic   \n",
       "G           bond:CX_halide_aromatic-X_generic   \n",
       "S       bond:CC(=O)C_ketone_aliphatic_generic   \n",
       "N             bond:C(=O)N_carboxamide_generic   \n",
       "C           bond:CX_halide_aromatic-X_generic   \n",
       "R         chain:alkaneLinear_ethyl_C2(H_gt_1)   \n",
       "M                       ring:aromatic_benzene   \n",
       "L                 ring:hetero__6_6__Z_generic   \n",
       "D                     ring:hetero__5__Z_1_3-Z   \n",
       "\n",
       "                                            6  \\\n",
       "J          bond:COC_ether_aliphatic__aromatic   \n",
       "A               bond:CN_amine_ter-N_aliphatic   \n",
       "G             chain:alkaneBranch_neopentyl_C5   \n",
       "S                    bond:COC_ether_aliphatic   \n",
       "N                  bond:CN_amine_sec-NH_alkyl   \n",
       "C               bond:CN_amine_pri-NH2_generic   \n",
       "R           bond:CX_halide_aromatic-X_generic   \n",
       "M                bond:CN_amine_sec-NH_generic   \n",
       "L  chain:aromaticAlkane_Ph-C1_acyclic_generic   \n",
       "D       bond:CC(=O)C_ketone_aliphatic_generic   \n",
       "\n",
       "                                                7  \\\n",
       "J              bond:COH_alcohol_aliphatic_generic   \n",
       "A           bond:CC(=O)C_ketone_aliphatic_generic   \n",
       "G                         ring:hetero__5__Z_1_3-Z   \n",
       "S                      bond:CN_amine_sec-NH_alkyl   \n",
       "N                 bond:CN_amine_alicyclic_generic   \n",
       "C               chain:aromaticAlkane_Ph-C1_cyclic   \n",
       "R  chain:alkaneLinear_ethyl_C2_(connect_noZ_CN=4)   \n",
       "M               bond:CX_halide_aromatic-X_generic   \n",
       "L                 bond:C(=O)N_carboxamide_generic   \n",
       "D              bond:C(=O)O_carboxylicAcid_generic   \n",
       "\n",
       "                                            8  \\\n",
       "J                bond:CN_amine_sec-NH_generic   \n",
       "A                 chain:alkaneCyclic_hexyl_C6   \n",
       "G                 ring:hetero__6_6__Z_generic   \n",
       "S  chain:aromaticAlkane_Ph-C1_acyclic_generic   \n",
       "N          ring:hetero__6__N_pyridine_generic   \n",
       "C          ring:hetero__6__N_pyridine_generic   \n",
       "R                        ring:aromatic_phenyl   \n",
       "M                        ring:aromatic_phenyl   \n",
       "L                   bond:COH_alcohol_aromatic   \n",
       "D                        ring:aromatic_phenyl   \n",
       "\n",
       "                                            9  mean_average_precision  \\\n",
       "J                 ring:hetero__6_6__Z_generic                0.158193   \n",
       "A                    bond:COC_ether_aliphatic                0.216338   \n",
       "G                chain:alkaneLinear_propyl_C3                0.242896   \n",
       "S                  bond:COH_alcohol_sec-alkyl                0.248083   \n",
       "N                     ring:hetero__5__Z_1_3-Z                0.195870   \n",
       "C       bond:CC(=O)C_ketone_aliphatic_generic                0.233856   \n",
       "R  chain:aromaticAlkane_Ph-C1_acyclic_generic                0.207821   \n",
       "M            bond:C(=O)O_carboxylicAcid_alkyl                0.668128   \n",
       "L                    bond:COC_ether_aliphatic                0.123778   \n",
       "D         chain:alkaneLinear_ethyl_C2(H_gt_1)                0.256457   \n",
       "\n",
       "   mean_auroc  \n",
       "J    0.507341  \n",
       "A    0.647837  \n",
       "G    0.530556  \n",
       "S    0.743365  \n",
       "N    0.594190  \n",
       "C    0.655864  \n",
       "R    0.707437  \n",
       "M    0.793803  \n",
       "L    0.584656  \n",
       "D    0.688779  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "withdrawn",
   "language": "python",
   "name": "withdrawn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
